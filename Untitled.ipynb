{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88a992db-7113-470e-94f9-8859149dd692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (1.93.1)\n",
      "Requirement already satisfied: anthropic in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (0.57.1)\n",
      "Requirement already satisfied: google-generativeai in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (0.8.5)\n",
      "Requirement already satisfied: mistralai in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (1.9.1)\n",
      "Requirement already satisfied: cohere in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (5.15.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from google-generativeai) (2.25.1)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from google-generativeai) (2.175.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from google-generativeai) (2.40.3)\n",
      "Requirement already satisfied: protobuf in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from google-generativeai) (5.29.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.73.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.4.8)\n",
      "Requirement already satisfied: eval-type-backport>=0.2.0 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from mistralai) (0.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from mistralai) (2.9.0.post0)\n",
      "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from cohere) (1.11.1)\n",
      "Requirement already satisfied: httpx-sse==0.4.0 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from cohere) (0.4.0)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from cohere) (0.21.2)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from cohere) (2.32.4.20250611)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from tokenizers<1,>=0.15->cohere) (0.33.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->mistralai) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\100779076\\appdata\\local\\anaconda3\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai anthropic google-generativeai mistralai cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76f82ea0-1637-4b0f-976c-a418839288f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import requests\n",
    "from enum import Enum\n",
    "import google.generativeai as genai\n",
    "import anthropic\n",
    "from mistralai import Mistral\n",
    "import cohere\n",
    "import pickle\n",
    "\n",
    "TEMPERATURE = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "332c2eff-9b45-45ab-a1c3-8923b62fa595",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'COHERE_API_KEY'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cohere_client \u001b[38;5;241m=\u001b[39m cohere\u001b[38;5;241m.\u001b[39mClientV2(api_key\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOHERE_API_KEY\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      2\u001b[0m openai_client \u001b[38;5;241m=\u001b[39m OpenAI(api_key\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m perplexity_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPERPLEXITY_API_KEY\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\os.py:717\u001b[0m, in \u001b[0;36m_Environ.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    714\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencodekey(key)]\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m    716\u001b[0m     \u001b[38;5;66;03m# raise KeyError with the original key value\u001b[39;00m\n\u001b[1;32m--> 717\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecodevalue(value)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'COHERE_API_KEY'"
     ]
    }
   ],
   "source": [
    "cohere_client = cohere.ClientV2(api_key=os.environ['COHERE_API_KEY'])\n",
    "openai_client = OpenAI(api_key=os.environ['OPENAI_API_KEY'])\n",
    "perplexity_key = os.environ['PERPLEXITY_API_KEY']\n",
    "genai.configure(api_key=os.environ['GEMINI_API_KEY'])\n",
    "anthropic_client = anthropic.Anthropic(api_key=os.environ['ANTHROPIC_API_KEY'])\n",
    "mistral_client = Mistral(api_key=os.environ['MISTRAL_API_KEY'])\n",
    "grok_client = OpenAI(api_key=os.environ['XAI_API_KEY'], base_url=\"https://api.x.ai/v1\")\n",
    "qwen_client = OpenAI(api_key=os.getenv(\"ALIBABA_API_KEY\"),base_url=\"https://dashscope-intl.aliyuncs.com/compatible-mode/v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0544817e-15cd-40aa-8fa7-477d57c25c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLM(Enum):\n",
    "    CHATGPT = 1\n",
    "    CLAUDE = 2\n",
    "    PERPLEXITY = 3\n",
    "    GEMINI = 4\n",
    "    MISTRAL = 5\n",
    "    COHERE = 6\n",
    "    GROK = 7\n",
    "    QWEN = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "800fe94d-0d0d-49bb-a3be-ed818b3845fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(prompt, llm):\n",
    "    if llm == LLM.CHATGPT:\n",
    "        response = openai_client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt,\n",
    "                }\n",
    "            ],\n",
    "            model=\"gpt-4o-mini\",\n",
    "            temperature=TEMPERATURE\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    elif llm == LLM.PERPLEXITY:\n",
    "        url = \"https://api.perplexity.ai/chat/completions\"\n",
    "\n",
    "        payload = {\n",
    "            \"model\": \"llama-3.1-sonar-small-128k-online\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ],\n",
    "            \"max_tokens\": 1000,\n",
    "            \"temperature\": TEMPERATURE,\n",
    "            \"top_p\": 0.9,\n",
    "            \"return_citations\": True,\n",
    "            \"search_domain_filter\": [\"perplexity.ai\"],\n",
    "            \"return_images\": False,\n",
    "            \"return_related_questions\": False,\n",
    "            \"search_recency_filter\": \"month\",\n",
    "            \"top_k\": 0,\n",
    "            \"stream\": False,\n",
    "            \"presence_penalty\": 0,\n",
    "            \"frequency_penalty\": 1\n",
    "        }\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {perplexity_key}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.post(url, json=payload, headers=headers)\n",
    "            response.raise_for_status()  # Raise an exception for bad status codes\n",
    "            data = response.json()\n",
    "            \n",
    "            # Extract the actual response content from the Perplexity API response\n",
    "            if 'choices' in data and len(data['choices']) > 0:\n",
    "                return data['choices'][0]['message']['content']\n",
    "            else:\n",
    "                raise Exception(\"No content in response\")\n",
    "                \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            raise Exception(f\"Perplexity API error: {str(e)}\")\n",
    "    elif llm == LLM.GEMINI:\n",
    "        model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n",
    "        response = model.generate_content(prompt, generation_config=genai.types.GenerationConfig(temperature=TEMPERATURE))\n",
    "        return response.text\n",
    "    elif llm == LLM.CLAUDE:\n",
    "        message = anthropic_client.messages.create(\n",
    "            model = 'claude-3-5-sonnet-20241022',\n",
    "            max_tokens=1000,\n",
    "            temperature=TEMPERATURE,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt,\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        return message.content[0].text\n",
    "    elif llm == LLM.MISTRAL:\n",
    "        response = mistral_client.chat.complete(\n",
    "            model='mistral-large-latest',\n",
    "            temperature=TEMPERATURE,\n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt,\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    elif llm == LLM.COHERE:\n",
    "        response = cohere_client.chat(\n",
    "            model=\"command-r-plus-08-2024\",\n",
    "            temperature=TEMPERATURE,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return response.message.content[0].text\n",
    "    elif llm == LLM.GROK:\n",
    "        response = grok_client.chat.completions.create(\n",
    "            model=\"grok-beta\",\n",
    "            temperature=TEMPERATURE,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    elif llm == LLM.QWEN:       \n",
    "        response = qwen_client.chat.completions.create(\n",
    "            model=\"qwen-max-2025-01-25\",\n",
    "            messages=[\n",
    "              {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "              {'role': 'user', 'content': 'Which number is larger, 9.11 or 9.8?'}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
